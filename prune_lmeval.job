#!/bin/bash

#SBATCH --account=researchers
#SBATCH --output=logs/pruneeval/R-%x.%j.out      # Name of output file (%j expands to jobId)
#SBATCH --error=logs/pruneeval/R-%x.%j.err     # Error handling
#SBATCH --nodes=1                # Total number of nodes requested
#SBATCH --cpus-per-task=8        # Schedule 8 cores (includes hyperthreading)
#SBATCH --mem=100G
#SBATCH --constraint="gpu_rtx8000|gpu_a100_40gb|gpu_v100" # Use either a v100 or a100
#SBATCH --gres=gpu:1      #v100:1 or a100_40gb:1 on brown
#SBATCH --time=0-0:15:00          # Run time (hh:mm:ss) 
#SBATCH --partition=red,brown    # Run on either the red or brown queue

#srun hostname

nvidia-smi
module load Anaconda3
conda activate lmeval

metric=$1
model_name=$2
prunetask=$3
group_metric=$4
prunemethod=$5

path="/home/data_shares/mapillary/thesis_models/pruned_models/"

echo "mode_namel=${model_name}"
echo "prunetask=${prunetask}"
echo "prune_method=${prunemethod}"
echo "metric=${metric}"
echo "group_metric=${group_metric}"

python main.py $metric $model_name $path $prunetask $group_metric $prunemethod