{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from utils import *\n",
    "from prune import *\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"bigscience/bloom-560m\", output_attentions=True)\n",
    "n_layer, n_head = get_model_layers_and_heads(model.config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\n",
    "model.eval()\n",
    "\n",
    "prompts = get_prompts_from_file(\"paws_en\")\n",
    "\n",
    "prune_percent = 0.25\n",
    "n_groups = (n_head * n_layer) - int(n_layer * n_head * prune_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_dict, attentions, attention_vectors = get_clustering_dict(prompts, model, tokenizer, n_groups, \"cosine\",  n_layer, n_head, by_layer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_metric = 'cosine'\n",
    "if group_metric != 'random':\n",
    "    squaref = squareform(pdist(attention_vectors, metric=group_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of groups:  Counter({1: 257, 2: 12, 3: 7, 4: 6, 6: 3, 12: 1, 23: 1, 5: 1})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "pruning_log = []\n",
    "verbose = True\n",
    "for group in clustering_dict.values():\n",
    "    counter.update([len(group)])\n",
    "    group_scores = defaultdict(int)\n",
    "    if len(group) <= 1:\n",
    "        continue\n",
    "    if len(group) == 2:\n",
    "        # with 2 heads just keep the first 1\n",
    "        head_to_keep = group[0]\n",
    "    else:\n",
    "        if group_metric == 'random':\n",
    "            head_to_keep = random.choice(group)\n",
    "        else:\n",
    "            for head_id in group:\n",
    "                for head_id_2 in group:\n",
    "                    if head_id == head_id_2:\n",
    "                        continue\n",
    "                    head1 = head_id[0]*n_head + head_id[1]\n",
    "                    head2 = head_id_2[0]*n_head + head_id_2[1]\n",
    "                    group_scores[head_id] += squaref[head1, head2]\n",
    "            head_to_keep = min(group_scores, key=lambda k: group_scores[k])\n",
    "            \n",
    "    for head in group:\n",
    "        if head == head_to_keep:\n",
    "            continue\n",
    "        head_to_remove = head\n",
    "        pruning_log.append((head_to_keep, head_to_remove))\n",
    "        model = duplicate_prune(model, source_layer=head_to_keep[0], source_head=head_to_keep[1], target_layer=head_to_remove[0], target_head=head_to_remove[1])\n",
    "if verbose:\n",
    "    print(\"size of groups: \", counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruning_log[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
